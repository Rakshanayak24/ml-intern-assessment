"""
Attention package exports for scaled dot-product and multi-head attention.
"""


from .attention import scaled_dot_product_attention, MultiHeadAttention


__all__ = ["scaled_dot_product_attention", "MultiHeadAttention"]
